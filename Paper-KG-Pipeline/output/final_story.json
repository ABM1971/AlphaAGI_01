{
  "title": "Modality Credibility Routing: Mitigating Text-Dominant Bias in Audio-Text Large Language Models via Lightweight Gating for Robust Emotion Recognition",
  "abstract": "Audio-text large language models exhibit a critical text-dominant bias, where models over-rely on textual information while neglecting acoustic cues—analogous to hallucination phenomena in vision-language models. This bias severely degrades performance when text is adversarial, irrelevant, or misaligned with audio content. We present Modality Credibility Routing (MCR), a novel framework that dynamically assesses modality reliability and routes representations to appropriate expert pathways. MCR introduces text interference detection through energy-based features measuring representation confidence and temporal evidence capturing audio-text alignment consistency. A lightweight gating mechanism learns to estimate modality credibility scores, enabling inference-time routing between Joint (audio+text) and Audio-only experts without full model retraining. We systematically evaluate text-dominant bias under three experimental settings—faithful, adversarial, and irrelevant text—establishing the first comprehensive benchmark for audio-text model robustness. Experiments on IEMOCAP, MELD, and CMU-MOSEI with constructed adversarial variants demonstrate that MCR achieves robust emotion recognition while preserving performance on faithful inputs, reducing robustness drop by over 40% compared to standard fusion approaches.",
  "problem_framing": "We reframe multimodal emotion recognition from a simple audio-text fusion problem to a modality credibility challenge. Current audio-text large language models implicitly assume text reliability, treating textual and acoustic modalities as equally trustworthy. However, real-world scenarios frequently present misleading, adversarial, or irrelevant text that contradicts acoustic evidence. This text-dominant bias mirrors the hallucination problem in vision-language models, where modality misalignment leads to unreliable outputs. By reconceptualizing the task as one requiring dynamic credibility assessment—determining when to trust text versus audio—we transform robust emotion recognition into a modality routing problem that demands inference-time adaptation based on detected text interference patterns.",
  "gap_pattern": "Existing audio-text fusion methods fail to address text-dominant bias because they assume static modality contributions. Early and late fusion approaches treat modalities as equally reliable, while prompt-based audio-text LLMs inherit text-over-reliance from their language model foundations. Current debiasing techniques focus on training-time rebalancing rather than inference-time adaptation to adversarial inputs. Critically, hallucination mitigation advances in vision-language models—including latent space steering and multimodal alignment—remain unexplored for audio-text domains. No existing framework provides: (1) systematic evaluation under faithful/adversarial/irrelevant settings, (2) dynamic credibility estimation for modality routing, or (3) lightweight intervention mechanisms that preserve faithful-setting performance while defending against text interference.",
  "solution": "Modality Credibility Routing transforms text-dominant bias mitigation from static fusion rebalancing into dynamic inference-time adaptation. Our framework first constructs 'text interference' representations by extracting energy-based features that measure representation magnitude and confidence divergence between modalities, combined with temporal evidence capturing audio-text alignment consistency across time windows. These features feed into lightweight gating networks trained via contrastive learning on constructed faithful/adversarial/irrelevant triplets, learning to distinguish reliable from misleading text without requiring full model retraining. At inference, the gating mechanism produces modality credibility scores that route inputs to either a Joint expert leveraging both modalities or an Audio-only expert grounded purely in acoustic evidence. This routing strategy, inspired by self-introspective decoding in VLM hallucination mitigation, enables the model to adaptively trust or discount textual information. Optional momentum-based consistency mechanisms stabilize audio representations across layers under text interference, ensuring robust emotion predictions regardless of text reliability conditions.",
  "method_skeleton": "Step 1: Construct text interference representations using energy-based features (representation magnitude, confidence divergence) and temporal evidence (audio-text alignment consistency over sliding windows); Step 2: Train lightweight gating networks and adapters via contrastive learning on faithful/adversarial/irrelevant triplets to estimate modality credibility scores; Step 3: Implement inference-time routing mechanism that selects Joint (audio+text) expert when text credibility is high or Audio-only expert when text interference is detected; Step 4: Apply preference optimization to refine gating decisions by distinguishing reliable from misleading text representations; Step 5: Integrate optional momentum-inspired consistency mechanisms across transformer layers to stabilize audio feature representations under varying text interference conditions",
  "innovation_claims": [
    "Transform the understanding of audio-text LLM reliability from assumed modality balance to systematic text-dominant bias analysis by establishing the first comprehensive experimental framework evaluating model behavior under faithful, adversarial, and irrelevant text settings, revealing critical vulnerabilities in current multimodal fusion approaches",
    "Reframe text interference detection from post-hoc error analysis to proactive credibility estimation by introducing a novel energy-based and temporal evidence framework that quantifies modality reliability, bridging hallucination mitigation techniques from vision-language models to the audio-text domain for the first time",
    "Transform robust multimodal emotion recognition from full model retraining to lightweight inference-time adaptation by developing gating and adapter mechanisms that enable dynamic expert routing based on modality credibility, achieving adversarial robustness with minimal computational overhead while preserving faithful-setting performance"
  ],
  "experiments_plan": "Datasets: IEMOCAP, MELD, CMU-MOSEI with constructed adversarial (emotion-contradicting) and irrelevant (random/unrelated) text variants. Metrics: Accuracy, weighted/unweighted F1, robustness drop, modality reliance ratio. Baselines: Early/late fusion, prompt-based audio-text LLMs, debiasing methods, adapted VLM hallucination techniques. Ablations: gating vs. adapter mechanisms, energy vs. temporal features, routing thresholds, expert selection strategies. Robustness analysis across adversarial intensity levels and cross-dataset generalization."
}